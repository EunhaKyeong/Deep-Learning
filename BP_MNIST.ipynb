{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "religious-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-defeat",
   "metadata": {},
   "source": [
    "## MNIST 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strong-warning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터 로드\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protective-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n",
      "[5 0 4 ... 5 6 8]\n",
      "(10000, 28, 28)\n",
      "10000\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# check mnist data shape\n",
    "print(train_images.shape)\n",
    "print(len(train_labels))\n",
    "print(train_labels)\n",
    "print(test_images.shape)\n",
    "print(len(test_labels))\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-mississippi",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-cathedral",
   "metadata": {},
   "source": [
    "## 모델 만들기\n",
    "- 하나의 model에는 여러 개의 layer가 존재하고, 하나의 layer에는 여러 개의 node가 존재한다.\n",
    "- `models.add()` : model에 layer를 추가한다.\n",
    "- `layers.Dense()` : Dense() 메서드의 매개변수로 layer에 대한 정보를 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "objective-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()    #network란 이름을 가진 model을 하나 만든다.\n",
    "#입력값으로 28*28 크기의 일차원 배열이 들어오고, node가 512개이며 활성화 함수가 relu인 layer를 생성한다.ㅠ\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28, )))     \n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-asian",
   "metadata": {},
   "source": [
    "### softmax 함수\n",
    "- output layer에서 많이 사용하는 활성화 함수이다.\n",
    "\n",
    "- 만약에 출력값이 y1~y10 총 10개라고 하자.\n",
    "- softmax 활성화 함수를 통해 output layer에서는 y1에서 y10까지 출력값의 범위를 0~1 사이인 실수로 변환한다.\n",
    "- 단,  `y1 + y2 + y3 +...+ y10 = 1`이어야 한다.\n",
    "\n",
    "이것이 의미하는 건 바로 각각의 출력값이 해당 input의 결과로 각각의 출력값을 갖게 될 `확률`을 의미한다.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-glass",
   "metadata": {},
   "source": [
    "## 손실 함수(loss function)\n",
    "- 실제값(목표값 또는 target)과 예측값(output layer에서 활성화 함수를 통해 얻은 값)의 차이를 구하는 함수\n",
    "- 손실 함수로도 여러가지가 존재하지만 오늘까지 배운 손실 함수는 `MSE, MAE, Cross Entropy`\n",
    "\n",
    "### 1. MSE\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOjubP%2FbtqGdzPuz5F%2FBOIrid8N4irE7w82WSaoy0%2Fimg.png' width='400px' height='200px'>\n",
    "\n",
    "- 예측값과 실제값의 차이를 `제곱`하여 더하는 함수\n",
    "- 오차가 클수록 제곱으로 인해 차이가 뚜렷해 오차를 확인하기 수월하다.\n",
    "\n",
    "### 2. MAE\n",
    "<img src='https://miro.medium.com/max/1210/1*ULbb_rvDsURwuRXZbG9YmA.png' width='400px' height='200px'>\n",
    "\n",
    "- 예측값과 실제값의 차이의 `절댓값`을 더하는 함수\n",
    "\n",
    "### 3. Categorical Cross Entropy\n",
    "<img src='https://user-images.githubusercontent.com/66666533/111270027-ae15f380-8672-11eb-9c54-db2373665fad.png' width='400px' height='400px'>\n",
    "\n",
    "- softmax의 손실함수로 많이 사용됨.\n",
    "- 카테고리(출력값)이 두개라면 Binary Cross Entropy 사용하면 된다.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Optimizer\n",
    "- gradient(미분값)을 통해 `weight의 변화를 주는 과정`\n",
    "- 이때 gradient는 활성화 함수를 미분한 값을 말한다.\n",
    "- Optimizer의 종류로는 `SGD, Momentum, NAG, Adagrad, Adadelta, Rmsprop` 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "shaped-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 모델은 rmsprop 방법을 사용해 optimizer를 수행하고, 손실 함수는 categorical_crossentropy 함수를 사용한다.\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-destination",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-tucson",
   "metadata": {},
   "source": [
    "## 데이터 전처리 - Scaling\n",
    "- 데이터가 너무 크거나 작을 때 학습을 시키다 보면 데이터가 0에 수렴하거나 발산해버리는 상황이 발생한다.\n",
    "- 또 데이터 갯수가 광범위할 때 학습 효율이 굉장히 떨어지게 된다.\n",
    "- 이를 방지하기 위해 데이터 전처리 과정을 거쳐야 한다.\n",
    "- 데이터 전처리 방법으로는 `scaling`과 `차원 축소`와 같은 방법이 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "metallic-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))    #차원 축소(3차원 배열->2차원 배열)\n",
    "train_images = train_images.astype('float32') / 255    #scaling\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
